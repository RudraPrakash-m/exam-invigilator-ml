Here is a **clean, professional `README.md`** that accurately reflects **what you have built till now** â€” no exaggeration, no missing pieces.
This is **submission-ready** and **viva-ready**.

---

# ğŸ“ Smart Exam Invigilator System (AI-Based)

An AI-powered smart exam invigilation system that detects suspicious student behavior in real time using **pose estimation + machine learning + rule-based logic**.
The system is designed to reduce manual monitoring effort while minimizing false alarms caused by normal movements.

---

## ğŸ“Œ Project Overview

Traditional exam invigilation relies heavily on human supervisors, which is error-prone and resource-intensive.
This project introduces an **automated invigilation system** that monitors students using a camera and identifies suspicious activities such as:

* Repeated head turning
* Looking sideways
* Hand movements towards nearby students
* Unusual body posture patterns

The system uses **YOLOv8 Pose Estimation** to extract keypoints and a **Machine Learning classifier** to analyze behavioral patterns over time.

---

## ğŸ§  Core Technologies Used

* **Python**
* **OpenCV** â€“ video capture & visualization
* **YOLOv8 Pose (Ultralytics)** â€“ human pose estimation
* **XGBoost** â€“ machine learning classifier
* **NumPy / Pandas** â€“ data processing
* **CSV logging & snapshot storage**

---

## ğŸ—ï¸ System Architecture

```
Camera (Webcam / IP Camera)
        â†“
YOLOv8 Pose Estimation
        â†“
Keypoint Extraction (Head, Shoulders, Hands)
        â†“
Temporal Feature Engineering (30-frame window)
        â†“
ML Model + Rule-Based Logic
        â†“
Suspicious / Normal Classification
        â†“
Logging + Snapshot Capture
```

---

## ğŸ“‚ Project Folder Structure

```
exam_invigilator_1/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ 1_extract_keypoints.py
â”‚   â”œâ”€â”€ 2_feature_engineering.py
â”‚   â”œâ”€â”€ 3_train_model.py
â”‚   â””â”€â”€ 4_live_detection.py   â† (current stable version)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ raw_keypoints.csv
â”‚   â””â”€â”€ window_features.csv
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cheating_model.json
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ events.csv
â”‚
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ *.jpg
â”‚
â”œâ”€â”€ yolo11s-pose.pt
â””â”€â”€ README.md
```

---

## âš™ï¸ How the System Works

### 1ï¸âƒ£ Pose Detection

* YOLOv8 Pose model detects human body keypoints in each frame.
* Keypoints include head, shoulders, wrists, etc.

### 2ï¸âƒ£ Temporal Analysis

* Keypoints are stored in a **sliding window of 30 frames** (~1 second).
* This avoids reacting to single-frame noise.

### 3ï¸âƒ£ Feature Extraction

Features currently used:

* Head movement magnitude (with noise threshold)
* Shoulder distance
* Left & right wrist movement

### 4ï¸âƒ£ Hybrid Decision Logic

* **ML Model (XGBoost)** predicts suspicious probability.
* **Rule-based overrides** detect clear hand movements.
* Small natural head movements are ignored using thresholds.

### 5ï¸âƒ£ Output

* Bounding box + label (`Normal` / `Suspicious`)
* Event logged to CSV
* Snapshot captured for evidence

---

## âœ… Key Improvements Implemented

âœ” Reduced false positives from natural head movement
âœ” Added hand-movement-based cheating detection
âœ” Used motion persistence instead of single-frame triggers
âœ” Hybrid ML + rule-based logic (industry practice)
âœ” Stable real-time performance

---

## ğŸ“Š Example Log Entry

```
timestamp, track_id, probability, severity, label
2025-01-04 11:32:15, 2, 0.91, , Suspicious
```

---

## ğŸ§ª How to Run the Project

### Install Dependencies

```bash
pip install ultralytics opencv-python xgboost numpy pandas
```

### Run Live Detection

```bash
python src/4_live_detection.py
```

Press **`q`** to exit.

---

## ğŸ“· Camera Support

* âœ” Laptop Webcam
* âœ” External USB Camera
* âœ” IP Webcam (Android phone) *(commented in code)*

---

## ğŸš§ Current Limitations

* No audio alerts (planned via ESP32)
* Does not yet detect student-to-student eye contact
* Works best for seated exam environments

---

## ğŸ”® Future Enhancements

* ESP32-based buzzer / speaker alerts
* Student interaction detection
* Eye gaze estimation
* Strike count per student
* Dashboard for supervisors
* Cloud-based logging

---

## ğŸ“ Academic Relevance

This project demonstrates:

* Computer Vision
* Temporal Machine Learning
* Hybrid AI system design
* Real-world false positive handling
* Practical surveillance system design

---

## ğŸ“¢ Final Note

This system is designed as an **assistive tool**, not a replacement for human invigilators.
All detections should be reviewed by a supervisor.

---

If you want next:

* **Architecture diagram (for PPT)**
* **Viva questions & answers**
* **Evaluation metrics section**
* **ESP32 integration README**

Just say the word.
